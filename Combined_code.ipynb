{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Source Code"
      ],
      "metadata": {
        "id": "JlMYhWrMXya6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nyRhNNVLEdkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maryam's section below"
      ],
      "metadata": {
        "id": "VvDOO6AroYfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofR0zPaPO0PY"
      },
      "outputs": [],
      "source": [
        "#Maryam\n",
        "\n",
        "#Importing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from google.colab import files\n",
        "dataset=files.upload()\n",
        "data= pd.read_csv('student-mat3.csv')\n",
        "data.info(verbose = True)\n",
        "\n",
        "#checking balance of data\n",
        "fail=0\n",
        "grades= data['G1']\n",
        "total = len (grades)\n",
        "for i in grades:\n",
        "  if i == 1:\n",
        "    fail=fail+1\n",
        "nb_pos = fail\n",
        "nb_neg = total - fail\n",
        "print(total)\n",
        "print(nb_pos)\n",
        "print(nb_neg)\n",
        "\n",
        "\n",
        "# splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data[['sex','age','address',\t'famsize',\t'Pstatus',\t'Medu',\t'Fedu',\t'Mjob',\t'Fjob',\t'reason',\t'guardian',\t'traveltime',\t'studytime',\t'failures',\t'schoolsup',\t'famsup',\t'paid',\t'activities',\t'nursery',\t'higher',\t'internet',\t'romantic',\t'famrel',\t'freetime',\t'goout', 'Dalc',\t'Walc',\t'health',\t'absences']]\n",
        "\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(X,data['G1'],\n",
        " test_size=0.2, shuffle = True, random_state = 0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        " test_size=0.5, random_state= 0)\n",
        "print(' X len: {}'.format(data.shape))\n",
        "print('X_train len: {}'.format(X_train.shape))\n",
        "print('X_test len: {}'.format(X_test.shape))\n",
        "print('X_val len: {}'.format(X_val.shape))\n",
        "\n",
        "\n",
        "# Find Optimal Maximum Depth\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "rec_train = []\n",
        "rec_val = []\n",
        "for i in range(1,10):\n",
        " dt = DecisionTreeClassifier(max_depth=i, min_impurity_decrease=0.01, random_state=0)\n",
        " dt.fit(X_train, y_train)\n",
        " rec_train.append(recall_score(y_train, dt.predict(X_train)))\n",
        " rec_val.append(recall_score(y_val, dt.predict(X_val)))\n",
        "plt.figure()\n",
        "plt.plot(rec_train,\"b\")\n",
        "plt.plot(rec_val, \"r\")\n",
        "plt.xlabel('Maximum Depth')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#find optimal Minimum Impurity Decrease\n",
        "rec_train = []\n",
        "rec_val = []\n",
        "for i in range(1,8):\n",
        " dt = DecisionTreeClassifier(max_depth=3, min_impurity_decrease=i/100)\n",
        " dt.fit(X_train, y_train)\n",
        " rec_train.append(recall_score(y_train, dt.predict(X_train)))\n",
        " rec_val.append(recall_score(y_val, dt.predict(X_val)))\n",
        "plt.figure()\n",
        "plt.plot(rec_train,\"b\")\n",
        "plt.plot(rec_val, \"r\")\n",
        "plt.xlabel('Minimum Impurity Decrease')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "clf1 = tree.DecisionTreeClassifier(max_depth=3, min_impurity_decrease=0)\n",
        "clf1.fit(X_train,y_train)\n",
        "print(clf1)\n",
        "yPredTrain = clf1.predict(X_train)\n",
        "yPredVal = clf1.predict(X_val)\n",
        "yPredTest = clf1.predict(X_test)\n",
        "accTrain = accuracy_score(y_train, yPredTrain)\n",
        "precTrain = precision_score(y_train, yPredTrain)\n",
        "recTrain = recall_score(y_train, yPredTrain)\n",
        "accVal = accuracy_score(y_val, yPredVal)\n",
        "precVal = precision_score(y_val, yPredVal)\n",
        "recVal = recall_score(y_val, yPredVal)\n",
        "accTest = accuracy_score(y_test, yPredTest)\n",
        "precTest = precision_score(y_test, yPredTest)\n",
        "recTest = recall_score(y_test, yPredTest)\n",
        "print('Accuracy on the train set: {}'.format(accTrain))\n",
        "print('Precision on the train set: {}'.format(precTrain))\n",
        "print('Recall on the train set: {}'.format(recTrain))\n",
        "print('Accuracy on the val set: {}'.format(accVal))\n",
        "print('Precision on the val set: {}'.format(precVal))\n",
        "print('Recall on the val set: {}'.format(recVal))\n",
        "\n",
        "print('Accuracy on the testing set: {}'.format(accTest))\n",
        "print('Precision on the testing set: {}'.format(precTest))\n",
        "print('Recall on the testing set: {}'.format(recTest))\n",
        "\n",
        "\n",
        "# Visualize Decision Tree\n",
        "import sklearn.tree as tree\n",
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf1, out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "predictors = X_train.columns\n",
        "dot_data = tree.export_graphviz(clf1, out_file=None,\n",
        " feature_names = predictors,\n",
        " class_names = ('pass', 'fail'),\n",
        " filled = True, rounded = True,\n",
        " special_characters = True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n",
        "\n",
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "y_pred = clf1.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "#feature importance\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "importances = clf1.feature_importances_\n",
        "\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Create the plot\n",
        "plt.title('Feature Importance')\n",
        "plt.bar(range(29), importances[indices], align='center')\n",
        "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jackson' Code"
      ],
      "metadata": {
        "id": "MEMGRaCw2mU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Jackson\n",
        "#Importing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import sklearn.tree as tree\n",
        "import graphviz\n",
        "\n",
        "# splitting the data\n",
        "X = data.drop(['G1n', 'G3n','G2n'], axis=1) #all except 'G1' G2'and 'G3'\n",
        "y= data['G2n'] # Target\n",
        "\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y,\n",
        " test_size=0.2, shuffle = True, random_state = 0)\n",
        "# Use the same function above for the validation set\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        " test_size=0.5, random_state= 0)\n",
        "\n",
        "# Find Optimal Maximum Depth\n",
        "acc_train = []\n",
        "acc_val = []\n",
        "\n",
        "for i in range (1,30):\n",
        " dt = RandomForestClassifier( max_depth = i, min_samples_split = 0.1,random_state= 0)\n",
        " dt.fit(X_train, y_train)\n",
        " ypred_train = RFC.predict(X_train)\n",
        " ypred_val = RFC.predict(X_val)\n",
        " ypred_test = RFC.predict(X_test)\n",
        " acc_train.append(accuracy_score(y_train, dt.predict(X_train)))\n",
        " acc_val.append(accuracy_score(y_val, dt.predict(X_val)))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(acc_train,'b')\n",
        "plt.plot(acc_val, 'r')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "max_accuracy = np.max(acc_val)\n",
        "plt.plot(7,max_accuracy, marker='x', markersize=15)\n",
        "plt.show()\n",
        "\n",
        "model = RandomForestClassifier(max_depth = 7, min_samples_split = 0.1)\n",
        "model = model.fit(X_train,y_train)\n",
        "ypred_train = model.predict(X_train)\n",
        "ypred_val = model.predict(X_val)\n",
        "ypred_test = model.predict(X_test)\n",
        "acc_train = accuracy_score(y_train, ypred_train)\n",
        "prec_train = precision_score(y_train,ypred_train)\n",
        "rec_train = recall_score(y_train,ypred_train)\n",
        "acc_val = accuracy_score(y_val, ypred_val)\n",
        "prec_val = precision_score(y_val,ypred_val)\n",
        "rec_val = recall_score(y_val,ypred_val)\n",
        "acc_test = accuracy_score(y_test, ypred_test)\n",
        "prec_test = precision_score(y_test,ypred_test)\n",
        "rec_test = recall_score(y_test,ypred_test)\n",
        "\n",
        "print('TRAIN')\n",
        "print('Accuracy Validation:{}'.format(acc_train))\n",
        "print('Precision Validation:{}'.format(prec_train))\n",
        "print('Recall Validation:{}'.format(rec_train))\n",
        "print('VALIDATION')\n",
        "print('Accuracy Validation:{}'.format(acc_val))\n",
        "print('Precision Validation:{}'.format(prec_val))\n",
        "print('Recall Validation:{}'.format(rec_val))\n",
        "print('TEST')\n",
        "print('Accuracy Test:{}'.format(acc_test))\n",
        "print('Precision Test:{}'.format(prec_test))\n",
        "print('Recall Test:{}'.format(rec_test))\n",
        "\n",
        "#Find Minimum Samples Split\n",
        "acc_train = []\n",
        "acc_val = []\n",
        "samples = np.linspace(0.01,1,10, endpoint = True)\n",
        "for i in samples:\n",
        " dt = RandomForestClassifier( max_depth = 7, min_samples_split = i, random_state = 0)\n",
        " dt.fit(X_train, y_train)\n",
        " ypred_train = model.predict(X_train)\n",
        " ypred_val = model.predict(X_val)\n",
        " ypred_test = model.predict(X_test)\n",
        " acc_train.append(accuracy_score(y_train, dt.predict(X_train)))\n",
        " acc_val.append(accuracy_score(y_val, dt.predict(X_val)))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(acc_train,'b')\n",
        "plt.plot(acc_val, 'r')\n",
        "plt.xlabel('Min Samples Split')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "max_accuracy = np.max(acc_val)\n",
        "print(max_accuracy)\n",
        "plt.plot(2,max_accuracy, marker='x', markersize=15)\n",
        "plt.show()\n",
        "\n",
        "model = RandomForestClassifier(max_depth = 7, min_samples_split = 2, random_state = 0 )\n",
        "model = model.fit(X_train,y_train)\n",
        "ypred_train = model.predict(X_train)\n",
        "ypred_val = model.predict(X_val)\n",
        "ypred_test = model.predict(X_test)\n",
        "acc_train = accuracy_score(y_train, ypred_train)\n",
        "prec_train = precision_score(y_train,ypred_train)\n",
        "rec_train = recall_score(y_train,ypred_train)\n",
        "acc_val = accuracy_score(y_val, ypred_val)\n",
        "prec_val = precision_score(y_val,ypred_val)\n",
        "rec_val = recall_score(y_val,ypred_val)\n",
        "acc_test = accuracy_score(y_test, ypred_test)\n",
        "prec_test = precision_score(y_test,ypred_test)\n",
        "rec_test = recall_score(y_test,ypred_test)\n",
        "\n",
        "print('TRAIN')\n",
        "print('Accuracy Validation:{}'.format(acc_train))\n",
        "print('Precision Validation:{}'.format(prec_train))\n",
        "print('Recall Validation:{}'.format(rec_train))\n",
        "print('VALIDATION')\n",
        "print('Accuracy Validation:{}'.format(acc_val))\n",
        "print('Precision Validation:{}'.format(prec_val))\n",
        "print('Recall Validation:{}'.format(rec_val))\n",
        "print('TEST')\n",
        "print('Accuracy Test:{}'.format(acc_test))\n",
        "print('Precision Test:{}'.format(prec_test))\n",
        "print('Recall Test:{}'.format(rec_test))\n",
        "\n",
        "#Find Minium Impurity Decrease\n",
        "acc_train = []\n",
        "acc_val = []\n",
        "samples = np.linspace(0.01,1,10, endpoint = True)\n",
        "for i in samples:\n",
        " dt = RandomForestClassifier(max_depth = 7, min_samples_split = 5, random_state= 0, min_impurity_decrease = i)\n",
        " dt.fit(X_train, y_train)\n",
        " ypred_val = model.predict(X_val)\n",
        " ypred_test = model.predict(X_test)\n",
        " acc_train.append(accuracy_score(y_train, dt.predict(X_train)))\n",
        " acc_val.append(accuracy_score(y_val, dt.predict(X_val)))\n",
        "plt.figure()\n",
        "plt.plot(acc_train,'b')\n",
        "plt.plot(acc_val, 'r')\n",
        "plt.xlabel('Min Impurity Decrease')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "max_accuracy = np.max(acc_val)\n",
        "print(max_accuracy)\n",
        "plt.plot(0,max_accuracy, marker='x', markersize=15)\n",
        "plt.show()\n",
        "\n",
        "#Find n-estimators\n",
        "acc_train = []\n",
        "acc_val = []\n",
        "for i in range (1,100):\n",
        " dt = RandomForestClassifier(max_depth = 7, min_samples_split = 5,\n",
        " random_state = 0, min_impurity_decrease = 0, max_samples = i)\n",
        " dt.fit(X_train, y_train)\n",
        " ypred_val = model.predict(X_val)\n",
        " ypred_test = model.predict(X_test)\n",
        " acc_train.append(accuracy_score(y_train, dt.predict(X_train)))\n",
        " acc_val.append(accuracy_score(y_val, dt.predict(X_val)))\n",
        "plt.figure()\n",
        "plt.plot(acc_train,'b')\n",
        "plt.plot(acc_val, 'r')\n",
        "plt.xlabel('N estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Data','Validation Data'])\n",
        "max_accuracy = np.max(acc_val)\n",
        "plt.plot(5,max_accuracy, marker='x', markersize=15)\n",
        "plt.show()\n",
        "\n",
        "# Build and train the Random Forest Model\n",
        "RFC =RandomForestClassifier(max_depth=7,min_samples_split=2,min_impurity_decrease = 0,  n_estimators = 4)\n",
        "RFC=RFC.fit(X_train,y_train)\n",
        "\n",
        "# Calculate the statistics of measure for the test and validation sets\n",
        "ypred_val = RFC.predict(X_val)\n",
        "ypred_test =RFC.predict(X_test)\n",
        "\n",
        "acc_val = accuracy_score(y_val,ypred_val)\n",
        "prec_val=precision_score(y_val,ypred_val)\n",
        "rec_val = recall_score(y_val, ypred_val)\n",
        "acc_test= accuracy_score(y_test,ypred_test)\n",
        "prec_test=precision_score(y_test,ypred_test)\n",
        "rec_test=recall_score(y_test,ypred_test)\n",
        "\n",
        "# Output Accuracy，Precision & Recall\n",
        "print('Val Precision:{}'.format(prec_val))\n",
        "print('Val Recall: {}'.format(rec_val))\n",
        "print('Val Accuracy: {}'. format(acc_val))\n",
        "print('Test Precision:{}'.format(prec_test))\n",
        "print('Test Recall: {}'.format(rec_test))\n",
        "print('Test Accuracy: {}'.format(acc_test))\n",
        "\n",
        "# Visualize Random Forest\n",
        "estimator = RFC.estimators_[3]\n",
        "dot_data=tree.export_graphviz(estimator, out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "predictors = X_train.columns\n",
        "do_data= tree.export_graphviz(estimator, out_file=None,\n",
        "                              feature_names = predictors,\n",
        "                              class_names = ('Negative','Positive'),\n",
        "                              filled = True, rounded = True,\n",
        "                              special_characters =True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n",
        "graph.format = 'png'\n",
        "graph.render('decision_tree')\n"
      ],
      "metadata": {
        "id": "-7Tk6If6O68j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ankita's Code"
      ],
      "metadata": {
        "id": "KPb4-mtW2rFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ankita\n",
        "import matplotlib.pyplot as plt #loading the poltting library\n",
        "import pandas as pd #loading the pandas module\n",
        "import numpy as np #loading the numpy module\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from scipy import stats\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "###\n",
        "warnings.filterwarnings('ignore')\n",
        "###\n",
        "\n",
        "#importing dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Reading dataset\n",
        "student_data = pd.read_csv('student-mat-1.csv')\n",
        "#viewing data set types\n",
        "student_data.info(verbose = True)\n",
        "\n",
        "student_data.head() #prints the first 5 rows\n",
        "features = student_data.dtypes\n",
        "print(features)\n",
        "\n",
        "#Undersampling the majority\n",
        "interest_columns = 'Gaveragen'\n",
        "#undersample majority\n",
        "notA = student_data.loc[student_data[interest_columns]==0].sample(107)\n",
        "student_data = pd.concat((student_data.loc[student_data[interest_columns]==1],notaboveB))\n",
        "\n",
        "print(len(notaboveB))\n",
        "\n",
        "#Checking distribution of both classes, getting above\n",
        "aboveB = 0\n",
        "grades = student_data['Gaveragen']\n",
        "total = len(grades)\n",
        "for i in grades:\n",
        "  if i ==1:\n",
        "    aboveB = aboveB+1\n",
        "nb_pos = aboveB\n",
        "nb_neg = total - aboveB\n",
        "print(total)\n",
        "print(nb_pos)\n",
        "print(nb_neg)\n",
        "\n",
        "#Cleaning Data removing object variables hot encoding was carried out in excel where categorical data was converted to binary\n",
        "student_data = student_data.select_dtypes(exclude = 'object')\n",
        "\n",
        "#Removing grades as the average grade is dependent on all those values\n",
        "removetest =['G1','G2','G3','G1n','G2n','G3n', 'Gaverage']\n",
        "student_data = student_data.drop(removetest, axis=1)\n",
        "\n",
        "#Predicting value as Gaveragen\n",
        "X = student_data.drop('Gaveragen', axis = 1).values\n",
        "y = student_data['Gaveragen'].values\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "#Using Lasso for feature selection\n",
        "from sklearn.linear_model import Lasso\n",
        "names = student_data.drop('Gaveragen', axis =1).columns\n",
        "print(names)\n",
        "\n",
        "#Prints the corressponding Lasso Coefficients for each feature and plots a graph\n",
        "lasso = Lasso(alpha = 0.01)\n",
        "lasso_coef=lasso.fit(X,y).coef_\n",
        "print(lasso_coef)\n",
        "\n",
        "_=plt.plot(range(len(names)), lasso_coef)\n",
        "\n",
        "_=plt.xticks(range(len(names)), names, rotation=90)\n",
        "\n",
        "_=plt.ylabel(\"Coefficients\")\n",
        "_=plt.figure(figsize=(20000,100))\n",
        "_=plt.show()\n",
        "\n",
        "\n",
        "#Heat map to show correlations\n",
        "#heatmaps\n",
        "correlations = student_data.corr()\n",
        "f, ax = plt.subplots(figsize = (11, 9))\n",
        "\n",
        "sns.heatmap(correlations, cmap = \"PuBu\", center = 0, vmin = -1, vmax = 1, square = True)\n",
        "\n",
        "b, t = plt.ylim()\n",
        "b += 0.5\n",
        "t -= 0.5\n",
        "plt.ylim(b, t)\n",
        "plt.show()\n",
        "\n",
        "#Class for modelSummary of logistic regression\n",
        "#returns the confusion matrix, accuracy, recall and precision\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "class ModelSummary:\n",
        "    \"\"\" This class extracts a summary of the model\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    get_se()\n",
        "        computes standard error\n",
        "    get_ci(SE_est)\n",
        "        computes confidence intervals\n",
        "    get_pvals()\n",
        "        computes p-values\n",
        "    get_summary(name=None)\n",
        "        prints the summary of the model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clf, X, y):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        clf: class\n",
        "            the classifier object model\n",
        "        X: pandas Dataframe\n",
        "            matrix of predictors\n",
        "        y: numpy array\n",
        "            matrix of variable\n",
        "        \"\"\"\n",
        "        self.clf = clf\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        pass\n",
        "\n",
        "    def get_se(self):\n",
        "        # from here https://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficients\n",
        "        predProbs = self.clf.predict_proba(self.X)\n",
        "        X_design = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
        "        V = np.diagflat(np.product(predProbs, axis=1))\n",
        "        covLogit = np.linalg.inv(np.dot(np.dot(X_design.T, V), X_design))\n",
        "        return np.sqrt(np.diag(covLogit))\n",
        "\n",
        "    def get_ci(self, SE_est):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        SE_est: numpy array\n",
        "            matrix of standard error estimations\n",
        "        \"\"\"\n",
        "        p = 0.975\n",
        "        df = len(self.X) - 2\n",
        "        crit_t_value = stats.t.ppf(p, df)\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        upper = coefs + (crit_t_value * SE_est)\n",
        "        lower = coefs - (crit_t_value * SE_est)\n",
        "        cis = np.zeros((len(coefs), 2))\n",
        "        cis[:,0] = lower\n",
        "        cis[:,1] = upper\n",
        "        return cis\n",
        "\n",
        "    def get_pvals(self):\n",
        "        # from here https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
        "        p = self.clf.predict_proba(self.X)\n",
        "        n = len(p)\n",
        "        m = len(self.clf.coef_[0]) + 1\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        se = self.get_se()\n",
        "        t =  coefs/se\n",
        "        p = (1 - stats.norm.cdf(abs(t))) * 2\n",
        "        return p\n",
        "\n",
        "    def get_summary(self, names=None):\n",
        "        ses = self.get_se()\n",
        "        cis = self.get_ci(ses)\n",
        "        lower = cis[:, 0]\n",
        "        upper = cis[:, 1]\n",
        "        pvals = self.get_pvals()\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        data = []\n",
        "        for i in range(len(coefs)):\n",
        "            currlist = []\n",
        "            currlist.append(np.round(coefs[i], 3))\n",
        "            currlist.append(np.round(ses[i], 3))\n",
        "            currlist.append(np.round(pvals[i], 3))\n",
        "            currlist.append(np.round(lower[i], 3))\n",
        "            currlist.append(np.round(upper[i], 3))\n",
        "            data.append(currlist)\n",
        "        cols = ['coefficient', 'std', 'p-value', '[0.025', '0.975]']\n",
        "        sumdf = pd.DataFrame(columns=cols, data=data)\n",
        "        if names is not None:\n",
        "            new_names = ['intercept']*(len(names) + 1)\n",
        "            new_names[1:] = [i for i in names]\n",
        "            sumdf.index = new_names\n",
        "        else:\n",
        "            try:\n",
        "                names = list(self.X.columns)\n",
        "                new_names = ['intercept']*(len(names) + 1)\n",
        "                new_names[1:] = [i for i in names]\n",
        "                sumdf.index = new_names\n",
        "            except:\n",
        "                pass\n",
        "        print(sumdf)\n",
        "        acc = accuracy_score(self.y, self.clf.predict(self.X))\n",
        "        rec = recall_score(self.y, self.clf.predict(self.X))\n",
        "        pre = precision_score(self.y, self.clf.predict(self.X))\n",
        "        confmat = confusion_matrix(self.y, self.clf.predict(self.X))\n",
        "        print('-'*60)\n",
        "        print('Confusion Matrix (total:{}) \\t Accuracy: \\t  {} \\t Recall: \\t  {} \\t Precision: \\t  {}'.format(len(self.X),np.round(acc, 3),(len(self.X),np.round(rec, 3)),(len(self.X),np.round(pre, 3))))\n",
        "        print('  TP: {} | FN: {}'.format(confmat[1][1],confmat[1][0]))\n",
        "        print('  FP: {} | TN: {}'.format(confmat[0][1],confmat[0][0]))\n",
        "\n",
        "#Choosing the features\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\n",
        "list_features =['Medu','Fedu','freetime','failures','romanticn','schoolsupn','Fjobn','Mjobn','studytime','paidn', 'healthn', 'highern','agen']\n",
        "#list_features =['Medu','Fedu','failures','romanticn','schoolsupn','Fjobn','Mjobn','studytime','paidn']\n",
        "\n",
        "X1 = student_data[list_features]\n",
        "y1 = student_data['Gaveragen'].values.reshape(-1,1)\n",
        "\n",
        "#Splitting the data\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(X1,y1,\n",
        " test_size=0.6, shuffle = True, random_state = 0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val,\n",
        " test_size=0.5, random_state= 0)\n",
        "\n",
        "print(' X len: {}'.format(student_data.shape))\n",
        "print('X_train len: {}'.format(X_train.shape))\n",
        "print('X_test len: {}'.format(X_test.shape))\n",
        "print('X_val len: {}'.format(X_val.shape))\n",
        "\n",
        "mod = LogisticRegression(C=1e9).fit(X_train,y_train)\n",
        "ModelSummary(mod,X_train,y_train).get_summary()\n",
        "\n",
        "mod = LogisticRegression(C=1e9).fit(X_val,y_val)\n",
        "ModelSummary(mod,X_val,y_val).get_summary()\n",
        "\n",
        "mod = LogisticRegression(C=10).fit(X_test,y_test)\n",
        "ModelSummary(mod,X_test,y_test).get_summary()\n",
        "\n",
        "\n",
        "#C vs Accuracy\n",
        "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1e9]\n",
        "\n",
        "val_accuracy_scores = []\n",
        "test_accuracy_scores = []\n",
        "\n",
        "for c in c_values:\n",
        "    # Create a logistic regression model with the current C value\n",
        "    logreg = LogisticRegression(C=c)\n",
        "\n",
        "    # Fit the model on your training data\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the target values for your validation data\n",
        "    y_val_pred = logreg.predict(X_val)\n",
        "\n",
        "    # Predict the target values for your testing data\n",
        "    y_test_pred = logreg.predict(X_test)\n",
        "\n",
        "     # Predict the target values for your testing data\n",
        "    y_train_pred = logreg.predict(X_train)\n",
        "\n",
        "\n",
        "    # Calculate the accuracy scores for validation and testing data\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    # Append the accuracy scores to their respective lists\n",
        "    val_accuracy_scores.append(val_accuracy)\n",
        "    test_accuracy_scores.append(test_accuracy)\n",
        "\n",
        "plt.plot(c_values, val_accuracy_scores, marker='o', label='Validation Data')\n",
        "plt.plot(c_values, test_accuracy_scores, marker='o', label='Testing Data')\n",
        "plt.xlabel('C value')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Accuracy Score vs. C value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Recall graph\n",
        "c_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "val_recall_scores = []\n",
        "train_recall_scores = []\n",
        "for c in c_values:\n",
        "    # Create a logistic regression model with the current C value\n",
        "    logreg = LogisticRegression(C=c)\n",
        "\n",
        "    # Fit the model on your training data\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the target values for your validation data\n",
        "    y_val_pred = logreg.predict(X_val)\n",
        "\n",
        "    # Predict the target values for your testing data\n",
        "    y_train_pred = logreg.predict(X_train)\n",
        "\n",
        "    # Calculate the recall scores for validation and testing data\n",
        "    val_recall = recall_score(y_val, y_val_pred)\n",
        "    train_recall = recall_score(y_train, y_train_pred)\n",
        "\n",
        "    # Append the recall scores to their respective lists\n",
        "    val_recall_scores.append(val_recall)\n",
        "    train_recall_scores.append(train_recall)\n",
        "\n",
        "  plt.plot(c_values, val_recall_scores, marker='o', label='Validation Data')\n",
        "plt.plot(c_values, test_recall_scores, marker='o', label='Training Data')\n",
        "plt.xlabel('C value')\n",
        "plt.ylabel('Recall Score')\n",
        "plt.title('Recall Score vs. C value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "JCZY44qxO7Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Site's Code"
      ],
      "metadata": {
        "id": "zbxb4LHL2ydL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Site\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "\"\"\"ModelSummary Class\"\"\"\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "class ModelSummary:\n",
        "    \"\"\" This class extracts a summary of the model\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    get_se()\n",
        "        computes standard error\n",
        "    get_ci(SE_est)\n",
        "        computes confidence intervals\n",
        "    get_pvals()\n",
        "        computes p-values\n",
        "    get_summary(name=None)\n",
        "        prints the summary of the model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clf, X, y):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        clf: class\n",
        "            the classifier object model\n",
        "        X: pandas Dataframe\n",
        "            matrix of predictors\n",
        "        y: numpy array\n",
        "            matrix of variable\n",
        "        \"\"\"\n",
        "        self.clf = clf\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        pass\n",
        "\n",
        "    def get_se(self):\n",
        "        # from here https://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficients\n",
        "        predProbs = self.clf.predict_proba(self.X)\n",
        "        X_design = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
        "        V = np.diagflat(np.product(predProbs, axis=1))\n",
        "        covLogit = np.linalg.inv(np.dot(np.dot(X_design.T, V), X_design))\n",
        "        return np.sqrt(np.diag(covLogit))\n",
        "\n",
        "    def get_ci(self, SE_est):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        SE_est: numpy array\n",
        "            matrix of standard error estimations\n",
        "        \"\"\"\n",
        "        p = 0.975\n",
        "        df = len(self.X) - 2\n",
        "        crit_t_value = stats.t.ppf(p, df)\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        upper = coefs + (crit_t_value * SE_est)\n",
        "        lower = coefs - (crit_t_value * SE_est)\n",
        "        cis = np.zeros((len(coefs), 2))\n",
        "        cis[:,0] = lower\n",
        "        cis[:,1] = upper\n",
        "        return cis\n",
        "\n",
        "    def get_pvals(self):\n",
        "        # from here https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
        "        p = self.clf.predict_proba(self.X)\n",
        "        n = len(p)\n",
        "        m = len(self.clf.coef_[0]) + 1\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        se = self.get_se()\n",
        "        t =  coefs/se\n",
        "        p = (1 - stats.norm.cdf(abs(t))) * 2\n",
        "        return p\n",
        "\n",
        "    def get_summary(self, names=None):\n",
        "        ses = self.get_se()\n",
        "        cis = self.get_ci(ses)\n",
        "        lower = cis[:, 0]\n",
        "        upper = cis[:, 1]\n",
        "        pvals = self.get_pvals()\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        data = []\n",
        "        for i in range(len(coefs)):\n",
        "            currlist = []\n",
        "            currlist.append(np.round(coefs[i], 3))\n",
        "            currlist.append(np.round(ses[i], 3))\n",
        "            currlist.append(np.round(pvals[i], 3))\n",
        "            currlist.append(np.round(lower[i], 3))\n",
        "            currlist.append(np.round(upper[i], 3))\n",
        "            data.append(currlist)\n",
        "        cols = ['coefficient', 'std', 'p-value', '[0.025', '0.975]']\n",
        "        sumdf = pd.DataFrame(columns=cols, data=data)\n",
        "        if names is not None:\n",
        "            new_names = ['intercept']*(len(names) + 1)\n",
        "            new_names[1:] = [i for i in names]\n",
        "            sumdf.index = new_names\n",
        "        else:\n",
        "            try:\n",
        "                names = list(self.X.columns)\n",
        "                new_names = ['intercept']*(len(names) + 1)\n",
        "                new_names[1:] = [i for i in names]\n",
        "                sumdf.index = new_names\n",
        "            except:\n",
        "                pass\n",
        "        print(sumdf)\n",
        "        acc = accuracy_score(self.y, self.clf.predict(self.X))\n",
        "        confmat = confusion_matrix(self.y, self.clf.predict(self.X))\n",
        "        print('-'*60)\n",
        "        print('Confusion Matrix (total:{}) \\t Accuracy: \\t  {}'.format(len(self.X),np.round(acc, 3)))\n",
        "        print('  TP: {} | FN: {}'.format(confmat[1][1],confmat[1][0]))\n",
        "        print('  FP: {} | TN: {}'.format(confmat[0][1],confmat[0][0]))\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import files\n",
        "dataset=files.upload()\n",
        "\n",
        "data=pd.read_csv(\"student.csv\")\n",
        "\n",
        "\n",
        "\n",
        "total = len(data)\n",
        "nb_pos = data['G3n'].sum()\n",
        "nb_neg = total - nb_pos\n",
        "print(nb_pos)\n",
        "print(nb_neg)\n",
        "# Undersample the majority class\n",
        "data_pos = data.loc[data[\"G3n\"] == 1]\n",
        "data_neg = data.loc[data[\"G3n\"] == 0].sample(nb_pos)\n",
        "\n",
        "# Combine the undersampled data\n",
        "resampled_data = pd.concat((data_pos, data_neg))\n",
        "\n",
        "y = resampled_data['G3n']  # Target (the 'G3' column)\n",
        "X = resampled_data.drop(['addressn', 'famsizen', 'nurseryn', 'healthn','traveltimen', 'guardiann','reasonn','internetn','studytimen','activitiesn','romanticn','freetimen','gooutn','Dalcn','Walcn','absencesn','G1n','G2n','G3n'], axis=1)  # Features (all columns except 'G3')\n",
        "X = pd.get_dummies(X, columns=['Fjobn', 'Mjobn'], prefix=['Fjobn', 'Mjobn']).drop(['Fjobn_1', 'Mjobn_1'], axis=1)\n",
        "\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y,\n",
        " test_size=0.2, shuffle = True, random_state = 0)\n",
        "# Use the same function above for the validation set\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val,\n",
        " test_size=0.5, random_state= 0)\n",
        "\n",
        "print('The sizes for train, validation, test should be {}'.format((len(X_train), len(X_val),len(X_test))))\n",
        "\n",
        "\"\"\"standardize\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform the training, validation, and test sets\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(X.columns)\n",
        "print(X_test)\n",
        "\n",
        "\"\"\"probability=True for estimation\"\"\"\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Create the SVM model\n",
        "\n",
        "model = SVC(probability=True,C=1,kernel= 'linear',gamma=0.005)\n",
        "model= model.fit(X_train,y_train)\n",
        "\n",
        "import seaborn as sns\n",
        "y_pred = model.predict(X_train)\n",
        "modsummary = ModelSummary(model, X_train, y_train)\n",
        "modsummary.get_summary()\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', ax=ax)\n",
        "\n",
        "# Set labels, title, and ticks\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Reality')\n",
        "ax.set_title('Confusion Matrix(Training)')\n",
        "ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "ax.yaxis.set_ticklabels(['Negative', 'Positive'])  # Swap the order of y-axis labels\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "recall = recall_score(y_train,y_pred)\n",
        "print(f\"recall: {recall}\")\n",
        "\n",
        "for k in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
        " model = SVC(kernel=k)\n",
        " model.fit(X_train, y_train)\n",
        " y_pred = model.predict(X_val)\n",
        " print(k)\n",
        " #print(accuracy_score(y_val,y_pred))\n",
        " accuracy = accuracy_score(y_val,y_pred)\n",
        " print(f\"accuracy: {accuracy}\")\n",
        " precision = precision_score(y_val,y_pred)\n",
        " print(f\"precision: {precision}\")\n",
        " recall = recall_score(y_val,y_pred)\n",
        " print(f\"recall: {recall}\")\n",
        "\n",
        "acc_train_c = []\n",
        "acc_val_c =[]\n",
        "rec_train_c = []\n",
        "rec_val_c =[]\n",
        "y_data_c = []\n",
        "\n",
        "print('TRAINING')\n",
        "for c in np.arange(0.1,10,0.05):\n",
        " y_data_c.append(c)\n",
        "\n",
        "print(y_data_c)\n",
        "for c in np.arange(0.1,10,0.05):\n",
        " model = SVC(kernel='rbf',C =c)\n",
        " model.fit(X_train, y_train)\n",
        " y_pred = model.predict(X_train)\n",
        " acc_train_c.append(precision_score(y_train, y_pred))\n",
        " rec_train_c.append(recall_score(y_train, y_pred))\n",
        "for c in np.arange(0.1, 10, 0.05):\n",
        " model = SVC(kernel='rbf',C =c)\n",
        " model.fit(X_train,y_train)\n",
        " y_pred = model.predict(X_val)\n",
        " acc_val_c.append(precision_score(y_val, y_pred))\n",
        " rec_val_c.append(recall_score(y_val, y_pred))\n",
        "# Plot a simple line chart\n",
        "plt.plot(y_data_c, acc_train_c, 'b', label = 'Training Set')\n",
        "plt.plot(y_data_c, acc_val_c, 'r', label = 'Validation Set')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('C')\n",
        "plt.title('Precision Scores of Training Set and Validation Set, varying C')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(y_data_c, rec_train_c, 'b', label = 'Training Set')\n",
        "plt.plot(y_data_c, rec_val_c, 'r', label = 'Validation Set')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('C')\n",
        "plt.title('Recall Scores of Training Set and Validation Set varying C')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model2 = SVC(kernel='rbf', C=1.2)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model2.predict(X_val)\n",
        "#print(accuracy_score(y_val,y_pred))\n",
        "accuracy = accuracy_score(y_val,y_pred)\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "precision = precision_score(y_val,y_pred)\n",
        "print(f\"precision: {precision}\")\n",
        "recall = recall_score(y_val,y_pred)\n",
        "print(f\"recall: {recall}\")\n",
        "\n",
        "\n",
        "y_predt = model2.predict(X_test)\n",
        "accuracyt = accuracy_score(y_test,y_predt)\n",
        "print(f\"accuracy: {accuracyt}\")\n",
        "precisiont = precision_score(y_test,y_predt)\n",
        "print(f\"precision: {precisiont}\")\n",
        "recallt = recall_score(y_test,y_predt)\n",
        "print(f\"recall: {recallt}\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid={'C':[0.1,1,20],'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'degree': [1,2,3,4,5,6]}\n",
        "grid = GridSearchCV(SVC(), param_grid)\n",
        "grid.fit(X_train,y_train)\n",
        "print(grid.best_params_)\n",
        "print(grid.score(X_test,y_test))\n",
        "\n",
        "acc_train_g = []\n",
        "acc_val_g =[]\n",
        "rec_train_g = []\n",
        "rec_val_g =[]\n",
        "y_data_g = []\n",
        "\n",
        "print('TRAINING')\n",
        "for g in np.arange(0.001,0.1,0.001):\n",
        " y_data_g.append(g)\n",
        "\n",
        "print(y_data_g)\n",
        "for g in np.arange(0.001,0.1,0.001):\n",
        " model = SVC(kernel='rbf',C = 1.2, gamma = g)\n",
        " model.fit(X_train, y_train)\n",
        " y_pred = model.predict(X_train)\n",
        " acc_train_g.append(precision_score(y_train, y_pred))\n",
        " rec_train_g.append(recall_score(y_train, y_pred))\n",
        "for g in np.arange(0.001,0.1,0.001):\n",
        " model = SVC(kernel='rbf',C = 1.2, gamma = g)\n",
        " model.fit(X_train,y_train)\n",
        " y_pred = model.predict(X_val)\n",
        " acc_val_g.append(precision_score(y_val, y_pred))\n",
        " rec_val_g.append(recall_score(y_val, y_pred))\n",
        "# Plot a simple line chart\n",
        "plt.plot(y_data_g, acc_train_g, 'b', label = 'Training Set')\n",
        "plt.plot(y_data_g, acc_val_g, 'r', label = 'Validation Set')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Gamma')\n",
        "plt.title('Precision Scores of Training Set and Validation Set, varying Gamma')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(y_data_g, rec_train_g, 'b', label = 'Training Set')\n",
        "plt.plot(y_data_g, rec_val_g, 'r', label = 'Validation Set')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Gamma')\n",
        "plt.title('Recall Scores of Training Set and Validation Set varying Gamma')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model3 = SVC(probability=True,kernel='rbf', C= 1.2,gamma = 0.075)\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "y_predtr = model3.predict(X_train)\n",
        "#print(accuracy_score(y_val,y_pred))\n",
        "accuracytr = accuracy_score(y_train,y_predtr)\n",
        "print(f\"accuracy: {accuracytr}\")\n",
        "precisiontr = precision_score(y_train,y_predtr)\n",
        "print(f\"precision: {precisiontr}\")\n",
        "recalltr = recall_score(y_train,y_predtr)\n",
        "print(f\"recall: {recalltr}\")\n",
        "\n",
        "y_pred = model3.predict(X_val)\n",
        "#print(accuracy_score(y_val,y_pred))\n",
        "accuracy = accuracy_score(y_val,y_pred)\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "precision = precision_score(y_val,y_pred)\n",
        "print(f\"precision: {precision}\")\n",
        "recall = recall_score(y_val,y_pred)\n",
        "print(f\"recall: {recall}\")\n",
        "\n",
        "y_predt = model3.predict(X_test)\n",
        "#print(accuracy_score(y_val,y_pred))\n",
        "accuracyt = accuracy_score(y_test,y_predt)\n",
        "print(f\"accuracy: {accuracyt}\")\n",
        "precisiont = precision_score(y_test,y_predt)\n",
        "print(f\"precision: {precisiont}\")\n",
        "recallt = recall_score(y_test,y_predt)\n",
        "print(f\"recall: {recallt}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_predt)\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', ax=ax)\n",
        "\n",
        "# Set labels, title, and ticks\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Reality')\n",
        "ax.set_title('Confusion Matrix(Training)')\n",
        "ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "ax.yaxis.set_ticklabels(['Negative', 'Positive'])  # Swap the order of y-axis labels\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "recall = recall_score(y_test,y_predt)\n",
        "print(f\"recall: {recall}\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Display boundary and support vectors\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "h = 0.02\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "meshgrid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "Z = model3.predict(pca.inverse_transform(meshgrid_points))\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap=plt.cm.RdBu, edgecolors='k')\n",
        "support_vectors_pca = pca.transform(model3.support_vectors_)\n",
        "plt.scatter(support_vectors_pca[:, 0], support_vectors_pca[:, 1],\n",
        "            facecolors='none', edgecolors='k', s=100, linewidths=1.5)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Decision Boundaries and Support Vectors')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RrKbXTNlO7ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avyay's section below"
      ],
      "metadata": {
        "id": "r6IwUc0ToVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV Import\n",
        "import pandas as pd\n",
        "\n",
        "studentData = pd.read_csv('student-mat.csv')\n",
        "\n",
        "#Plotting Final Grade histogram\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(studentData['G3'], bins = 20)\n",
        "plt.xlabel(\"Final Grade\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram of Final Grade\")\n",
        "plt.show()\n",
        "\n",
        "# First Logistic regression to find bad data points\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = studentData[['gooutn', 'Dalcn', 'Walcn','healthn', 'freetimen','famreln','romanticn','internetn','activitiesn','Mjobn','Fjobn','guardiann']]\n",
        "y = studentData['G3n'].values.reshape(-1, 1)\n",
        "\n",
        "mylr = LogisticRegression()\n",
        "mylr.fit(X, y)\n",
        "\n",
        "# Code to get Confusion matrix\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "class ModelSummary:\n",
        "    \"\"\" This class extracts a summary of the model\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    get_se()\n",
        "        computes standard error\n",
        "    get_ci(SE_est)\n",
        "        computes confidence intervals\n",
        "    get_pvals()\n",
        "        computes p-values\n",
        "    get_summary(name=None)\n",
        "        prints the summary of the model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clf, X, y):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        clf: class\n",
        "            the classifier object model\n",
        "        X: pandas Dataframe\n",
        "            matrix of predictors\n",
        "        y: numpy array\n",
        "            matrix of variable\n",
        "        \"\"\"\n",
        "        self.clf = clf\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        pass\n",
        "\n",
        "    def get_se(self):\n",
        "        # from here https://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficients\n",
        "        predProbs = self.clf.predict_proba(self.X)\n",
        "        X_design = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
        "        V = np.diagflat(np.product(predProbs, axis=1))\n",
        "        covLogit = np.linalg.inv(np.dot(np.dot(X_design.T, V), X_design))\n",
        "        return np.sqrt(np.diag(covLogit))\n",
        "\n",
        "    def get_ci(self, SE_est):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        SE_est: numpy array\n",
        "            matrix of standard error estimations\n",
        "        \"\"\"\n",
        "        p = 0.975\n",
        "        df = len(self.X) - 2\n",
        "        crit_t_value = stats.t.ppf(p, df)\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        upper = coefs + (crit_t_value * SE_est)\n",
        "        lower = coefs - (crit_t_value * SE_est)\n",
        "        cis = np.zeros((len(coefs), 2))\n",
        "        cis[:,0] = lower\n",
        "        cis[:,1] = upper\n",
        "        return cis\n",
        "\n",
        "    def get_pvals(self):\n",
        "        # from here https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
        "        p = self.clf.predict_proba(self.X)\n",
        "        n = len(p)\n",
        "        m = len(self.clf.coef_[0]) + 1\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        se = self.get_se()\n",
        "        t =  coefs/se\n",
        "        p = (1 - stats.norm.cdf(abs(t))) * 2\n",
        "        return p\n",
        "\n",
        "    def get_summary(self, names=None):\n",
        "        ses = self.get_se()\n",
        "        cis = self.get_ci(ses)\n",
        "        lower = cis[:, 0]\n",
        "        upper = cis[:, 1]\n",
        "        pvals = self.get_pvals()\n",
        "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
        "        data = []\n",
        "        for i in range(len(coefs)):\n",
        "            currlist = []\n",
        "            currlist.append(np.round(coefs[i], 3))\n",
        "            currlist.append(np.round(ses[i], 3))\n",
        "            currlist.append(np.round(pvals[i], 3))\n",
        "            currlist.append(np.round(lower[i], 3))\n",
        "            currlist.append(np.round(upper[i], 3))\n",
        "            data.append(currlist)\n",
        "        cols = ['coefficient', 'std', 'p-value', '[0.025', '0.975]']\n",
        "        sumdf = pd.DataFrame(columns=cols, data=data)\n",
        "        if names is not None:\n",
        "            new_names = ['intercept']*(len(names) + 1)\n",
        "            new_names[1:] = [i for i in names]\n",
        "            sumdf.index = new_names\n",
        "        else:\n",
        "            try:\n",
        "                names = list(self.X.columns)\n",
        "                new_names = ['intercept']*(len(names) + 1)\n",
        "                new_names[1:] = [i for i in names]\n",
        "                sumdf.index = new_names\n",
        "            except:\n",
        "                pass\n",
        "        print(sumdf)\n",
        "        acc = accuracy_score(self.y, self.clf.predict(self.X))\n",
        "        confmat = confusion_matrix(self.y, self.clf.predict(self.X))\n",
        "        print('-'*60)\n",
        "        print('Confusion Matrix (total:{}) \\t Accuracy: \\t  {}'.format(len(self.X),np.round(acc, 3)))\n",
        "        print('  TP: {} | FN: {}'.format(confmat[1][1],confmat[1][0]))\n",
        "        print('  FP: {} | TN: {}'.format(confmat[0][1],confmat[0][0]))\n",
        "\n",
        "\n",
        "# Obtain first confusion matrix with p-values\n",
        "modsummary = ModelSummary(mylr, X, y)\n",
        "modsummary.get_summary()\n",
        "\n",
        "#After features removed, following code creates correlation heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot = sns.heatmap(X_train.corr(), cmap = \"PuBu\")\n",
        "plt.title(\"Correlations\")\n",
        "plt.show()\n",
        "\n",
        "#After features removed, following code creates balanced dataset\n",
        "total = len(studentData)\n",
        "nFails = studentData['G3n'].sum()\n",
        "nPasses = nFails\n",
        "print(nFails)\n",
        "studentFails = studentData.loc[studentData['G3n'] == 1]\n",
        "studentPasses = studentData.loc[studentData['G3n'] == 0].sample(nPasses)\n",
        "\n",
        "resampled_studentData = pd.concat((studentFails, studentPasses))\n",
        "\n",
        "X_new = resampled_studentData[['gooutn', 'Dalcn', 'Walcn', 'freetimen','romanticn','internetn','activitiesn']]\n",
        "y_new = resampled_studentData['G3n'].values.reshape(-1, 1)\n",
        "\n",
        "mylr2 = LogisticRegression()\n",
        "mylr2.fit(X_new, y_new)\n",
        "\n",
        "# Confusion matrix of resampled data\n",
        "modsummary = ModelSummary(mylr2, X_new, y_new)\n",
        "modsummary.get_summary()\n",
        "\n",
        "#Data split for training, validation, and testing\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(X_new, y_new, test_size=0.2, shuffle = True, random_state = 0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.5, shuffle = True, random_state = 0)\n",
        "print(len(y_val), len(y_test), len(y_train))\n",
        "\n",
        "#Training and validation standardization\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train = (X_train - X_means) / X_stds\n",
        "X_val = (X_val - X_means) / X_stds\n",
        "\n",
        "#Graphing kernel values\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "kernelList = ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "\n",
        "accListt = []\n",
        "precListt = []\n",
        "recListt = []\n",
        "accListv = []\n",
        "precListv = []\n",
        "recListv = []\n",
        "\n",
        "for kernelType in kernelList:\n",
        "  model = SVC(C = 1, kernel = kernelType, gamma = 0.05)\n",
        "  model = model.fit(X_train, y_train)\n",
        "  ypredt = model.predict(X_train)\n",
        "  ypredv = model.predict(X_val)\n",
        "\n",
        "  acct = accuracy_score(y_train, ypredt)\n",
        "  prect = precision_score(y_train, ypredt)\n",
        "  rect = recall_score(y_train, ypredt)\n",
        "\n",
        "  accv = accuracy_score(y_val, ypredv)\n",
        "  precv = precision_score(y_val, ypredv)\n",
        "  recv = recall_score(y_val, ypredv)\n",
        "\n",
        "  accListt.append(acct)\n",
        "  precListt.append(prect)\n",
        "  recListt.append(rect)\n",
        "  accListv.append(accv)\n",
        "  precListv.append(precv)\n",
        "  recListv.append(recv)\n",
        "\n",
        "plt.plot(kernelList, accListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(kernelList, accListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(kernelList, accListt, \"o\", color = \"red\")\n",
        "plt.plot(kernelList, accListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Kernel type\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. Kernel type (gamma = 0.05 and C = 1)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(kernelList, precListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(kernelList, precListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(kernelList, precListt, \"o\", color = \"red\")\n",
        "plt.plot(kernelList, precListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Kernel type\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision vs. Kernel type (gamma = 0.05 and C = 1)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(kernelList, recListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(kernelList, recListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(kernelList, recListt, \"o\", color = \"red\")\n",
        "plt.plot(kernelList, recListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Kernel type\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs. Kernel type (gamma = 0.05 and C = 1)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Graphing C-value\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "cList = [1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]\n",
        "\n",
        "accListt = []\n",
        "precListt = []\n",
        "recListt = []\n",
        "accListv = []\n",
        "precListv = []\n",
        "recListv = []\n",
        "\n",
        "for cval in cList:\n",
        "  model = SVC(C = cval, kernel = \"rbf\", gamma = 0.05)\n",
        "  model = model.fit(X_train, y_train)\n",
        "  ypredt = model.predict(X_train)\n",
        "  ypredv = model.predict(X_val)\n",
        "\n",
        "  acct = accuracy_score(y_train, ypredt)\n",
        "  prect = precision_score(y_train, ypredt)\n",
        "  rect = recall_score(y_train, ypredt)\n",
        "\n",
        "  accv = accuracy_score(y_val, ypredv)\n",
        "  precv = precision_score(y_val, ypredv)\n",
        "  recv = recall_score(y_val, ypredv)\n",
        "\n",
        "  accListt.append(acct)\n",
        "  precListt.append(prect)\n",
        "  recListt.append(rect)\n",
        "  accListv.append(accv)\n",
        "  precListv.append(precv)\n",
        "  recListv.append(recv)\n",
        "\n",
        "\n",
        "plt.plot(cList, accListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(cList, accListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(cList, accListt, \"o\", color = \"red\")\n",
        "plt.plot(cList, accListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"C value\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. C value (rbf kernel and gamma = 0.05)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cList, precListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(cList, precListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(cList, precListt, \"o\", color = \"red\")\n",
        "plt.plot(cList, precListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"C value\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision vs. C value (rbf kernel and gamma = 0.05)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cList, recListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(cList, recListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(cList, recListt, \"o\", color = \"red\")\n",
        "plt.plot(cList, recListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"C value\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs. C value (rbf kernel and gamma = 0.05)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Graphing Gamma value\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "gammaList = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "accListt = []\n",
        "precListt = []\n",
        "recListt = []\n",
        "accListv = []\n",
        "precListv = []\n",
        "recListv = []\n",
        "\n",
        "for gammaval in gammaList:\n",
        "  model = SVC(C = 9.5, kernel = \"rbf\", gamma = gammaval)\n",
        "  model = model.fit(X_train, y_train)\n",
        "  ypredt = model.predict(X_train)\n",
        "  ypredv = model.predict(X_val)\n",
        "\n",
        "  acct = accuracy_score(y_train, ypredt)\n",
        "  prect = precision_score(y_train, ypredt)\n",
        "  rect = recall_score(y_train, ypredt)\n",
        "\n",
        "  accv = accuracy_score(y_val, ypredv)\n",
        "  precv = precision_score(y_val, ypredv)\n",
        "  recv = recall_score(y_val, ypredv)\n",
        "\n",
        "  accListt.append(acct)\n",
        "  precListt.append(prect)\n",
        "  recListt.append(rect)\n",
        "  accListv.append(accv)\n",
        "  precListv.append(precv)\n",
        "  recListv.append(recv)\n",
        "\n",
        "\n",
        "plt.plot(gammaList, accListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(gammaList, accListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(gammaList, accListt, \"o\", color = \"red\")\n",
        "plt.plot(gammaList, accListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Gamma\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. Gamma (rbf kernel and C = 9.5)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(gammaList, precListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(gammaList, precListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(gammaList, precListt, \"o\", color = \"red\")\n",
        "plt.plot(gammaList, precListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Gamma\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision vs. Gamma (rbf kernel and C = 9.5)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(gammaList, recListt, color = \"red\", label = \"Training set\")\n",
        "plt.plot(gammaList, recListv, color = \"blue\", label = \"Validation set\")\n",
        "plt.plot(gammaList, recListt, \"o\", color = \"red\")\n",
        "plt.plot(gammaList, recListv, \"o\", color = \"blue\")\n",
        "plt.xlabel(\"Gamma\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs. Gamma (rbf kernel and C = 9.5)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Optimized model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(C = 9.5, kernel = 'rbf', gamma = 0.1)\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "ypredt = model.predict(X_train)\n",
        "ypredv = model.predict(X_val)\n",
        "ypredte = model.predict(X_test)\n",
        "\n",
        "acct = accuracy_score(y_train, ypredt)\n",
        "prect = precision_score(y_train, ypredt)\n",
        "rect = recall_score(y_train, ypredt)\n",
        "\n",
        "accv = accuracy_score(y_val, ypredv)\n",
        "precv = precision_score(y_val, ypredv)\n",
        "recv = recall_score(y_val, ypredv)\n",
        "\n",
        "accte = accuracy_score(y_test, ypredte)\n",
        "precte = precision_score(y_test, ypredte)\n",
        "recte = recall_score(y_test, ypredte)\n",
        "\n",
        "print(acct, prect, rect)\n",
        "print(accv, precv, recv)\n",
        "print(accte, precte, recte)\n",
        "\n",
        "#Confusion matrix for SVM\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "titles_options = [\n",
        "    (\"Confusion matrix, without normalization\", None),\n",
        "    (\"Normalized confusion matrix\", \"true\"),\n",
        "]\n",
        "for title, normalize in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        model,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        #display_labels=class_names,\n",
        "        cmap=plt.cm.Blues,\n",
        "        normalize=normalize,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MWryk_h_2Wv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#General Code for Group Components"
      ],
      "metadata": {
        "id": "og9ZJCv9AKJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap for Conclusion\n",
        "import pandas as pd\n",
        "\n",
        "studentDataNum = pd.read_csv(\"student-mat-num.csv\")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot = sns.heatmap(studentDataNum.corr(), cmap = \"PuBu\")\n",
        "plt.title(\"Correlations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZHH__qrW-3wv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}